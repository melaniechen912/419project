{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016871,
     "end_time": "2023-04-23T22:13:34.652773",
     "exception": false,
     "start_time": "2023-04-23T22:13:34.635902",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Simple PyTorch Training pipeline to train using SnapMix Augmentation.** \n",
    "\n",
    "*References :* \n",
    "* https://arxiv.org/abs/2012.04846\n",
    "* https://github.com/Shaoli-Huang/SnapMix\n",
    "\n",
    "\n",
    "* V15 : Base version\n",
    "* V17 : Added warmup epoch(1), reducing snapmix to 0.5, Moved back prop etc outside autocast(as suggested in docs)\n",
    "* V18 : Increased lr of backbone and running for 10 epochs now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-23T22:13:34.690522Z",
     "iopub.status.busy": "2023-04-23T22:13:34.689681Z",
     "iopub.status.idle": "2023-04-23T22:13:52.105489Z",
     "shell.execute_reply": "2023-04-23T22:13:52.104967Z",
     "shell.execute_reply.started": "2023-04-23T17:12:31.560271Z"
    },
    "papermill": {
     "duration": 17.437087,
     "end_time": "2023-04-23T22:13:52.105612",
     "exception": false,
     "start_time": "2023-04-23T22:13:34.668525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timm\r\n",
      "  Downloading timm-0.6.13-py3-none-any.whl (549 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 549 kB 13.0 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from timm) (5.3.1)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm) (0.8.1)\r\n",
      "Requirement already satisfied: torch>=1.7 in /opt/conda/lib/python3.7/site-packages (from timm) (1.7.0)\r\n",
      "Collecting huggingface-hub\r\n",
      "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 200 kB 59.6 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (3.0.10)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (2.23.0)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (4.45.0)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (3.1.1)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from timm) (5.3.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface-hub->timm) (3.1.0)\r\n",
      "Collecting packaging>=20.9\r\n",
      "  Downloading packaging-23.1-py3-none-any.whl (48 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 48 kB 5.2 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (2020.12.5)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (2.9)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (1.25.9)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (3.0.4)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=1.7->timm) (0.18.2)\r\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch>=1.7->timm) (0.6)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch>=1.7->timm) (1.18.5)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch>=1.7->timm) (1.18.5)\r\n",
      "Requirement already satisfied: torch>=1.7 in /opt/conda/lib/python3.7/site-packages (from timm) (1.7.0)\r\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (8.0.1)\r\n",
      "Collecting typing-extensions>=3.7.4.3\r\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\r\n",
      "Installing collected packages: typing-extensions, packaging, huggingface-hub, timm\r\n",
      "  Attempting uninstall: typing-extensions\r\n",
      "    Found existing installation: typing-extensions 3.7.4.1\r\n",
      "    Uninstalling typing-extensions-3.7.4.1:\r\n",
      "      Successfully uninstalled typing-extensions-3.7.4.1\r\n",
      "  Attempting uninstall: packaging\r\n",
      "    Found existing installation: packaging 20.1\r\n",
      "    Uninstalling packaging-20.1:\r\n",
      "      Successfully uninstalled packaging-20.1\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bokeh 2.2.3 requires tornado>=5.1, but you have tornado 5.0.2 which is incompatible.\r\n",
      "aiobotocore 1.1.2 requires botocore<1.17.45,>=1.17.44, but you have botocore 1.19.31 which is incompatible.\u001b[0m\r\n",
      "Successfully installed huggingface-hub-0.13.4 packaging-23.1 timm-0.6.13 typing-extensions-4.5.0\r\n",
      "\u001b[33mWARNING: You are using pip version 20.3.1; however, version 23.1.1 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2023-04-23T22:13:52.154645Z",
     "iopub.status.busy": "2023-04-23T22:13:52.153571Z",
     "iopub.status.idle": "2023-04-23T22:13:55.843458Z",
     "shell.execute_reply": "2023-04-23T22:13:55.842433Z",
     "shell.execute_reply.started": "2023-04-23T17:12:50.132198Z"
    },
    "papermill": {
     "duration": 3.716854,
     "end_time": "2023-04-23T22:13:55.843581",
     "exception": false,
     "start_time": "2023-04-23T22:13:52.126727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import timm\n",
    "from torchvision import models as tvmodels\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-23T22:13:55.888655Z",
     "iopub.status.busy": "2023-04-23T22:13:55.887906Z",
     "iopub.status.idle": "2023-04-23T22:13:55.892966Z",
     "shell.execute_reply": "2023-04-23T22:13:55.892500Z",
     "shell.execute_reply.started": "2023-04-23T17:12:53.823797Z"
    },
    "papermill": {
     "duration": 0.029109,
     "end_time": "2023-04-23T22:13:55.893072",
     "exception": false,
     "start_time": "2023-04-23T22:13:55.863963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from albumentations import Compose\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-23T22:13:55.938446Z",
     "iopub.status.busy": "2023-04-23T22:13:55.937719Z",
     "iopub.status.idle": "2023-04-23T22:13:55.940333Z",
     "shell.execute_reply": "2023-04-23T22:13:55.940807Z",
     "shell.execute_reply.started": "2023-04-23T17:12:53.832968Z"
    },
    "papermill": {
     "duration": 0.027169,
     "end_time": "2023-04-23T22:13:55.940991",
     "exception": false,
     "start_time": "2023-04-23T22:13:55.913822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-23T22:13:55.986310Z",
     "iopub.status.busy": "2023-04-23T22:13:55.985625Z",
     "iopub.status.idle": "2023-04-23T22:13:55.989185Z",
     "shell.execute_reply": "2023-04-23T22:13:55.988733Z",
     "shell.execute_reply.started": "2023-04-23T17:12:53.843952Z"
    },
    "papermill": {
     "duration": 0.027976,
     "end_time": "2023-04-23T22:13:55.989287",
     "exception": false,
     "start_time": "2023-04-23T22:13:55.961311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_PATH = '../input/cassava-leaf-disease-classification/'\n",
    "NUM_FOLDS = 5\n",
    "bs = 32\n",
    "# Running only 5 epochs to test (Train more offline ^_^)\n",
    "EPOCHS = 10\n",
    "sz = 512\n",
    "SNAPMIX_ALPHA = 5.0\n",
    "SNAPMIX_PCT = 0.5\n",
    "GRAD_ACCUM_STEPS = 1\n",
    "TIMM_MODEL = 'resnet50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-23T22:13:56.033150Z",
     "iopub.status.busy": "2023-04-23T22:13:56.032451Z",
     "iopub.status.idle": "2023-04-23T22:13:56.034888Z",
     "shell.execute_reply": "2023-04-23T22:13:56.035438Z",
     "shell.execute_reply.started": "2023-04-23T17:12:53.854015Z"
    },
    "papermill": {
     "duration": 0.026377,
     "end_time": "2023-04-23T22:13:56.035560",
     "exception": false,
     "start_time": "2023-04-23T22:13:56.009183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO : Play around with SNAPMIX_PCT, SNAPMIX_ALPHA and EPOCHS to converge for max accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-23T22:13:56.082184Z",
     "iopub.status.busy": "2023-04-23T22:13:56.081511Z",
     "iopub.status.idle": "2023-04-23T22:13:56.087920Z",
     "shell.execute_reply": "2023-04-23T22:13:56.087476Z",
     "shell.execute_reply.started": "2023-04-23T17:12:53.865327Z"
    },
    "papermill": {
     "duration": 0.032509,
     "end_time": "2023-04-23T22:13:56.088025",
     "exception": false,
     "start_time": "2023-04-23T22:13:56.055516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "SEED = 1234\n",
    "seed_everything(SEED)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020105,
     "end_time": "2023-04-23T22:13:56.128254",
     "exception": false,
     "start_time": "2023-04-23T22:13:56.108149",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Cassava Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-23T22:13:56.178327Z",
     "iopub.status.busy": "2023-04-23T22:13:56.177515Z",
     "iopub.status.idle": "2023-04-23T22:13:56.180755Z",
     "shell.execute_reply": "2023-04-23T22:13:56.180249Z",
     "shell.execute_reply.started": "2023-04-23T17:13:02.616421Z"
    },
    "papermill": {
     "duration": 0.03245,
     "end_time": "2023-04-23T22:13:56.180877",
     "exception": false,
     "start_time": "2023-04-23T22:13:56.148427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CassavaDataset(Dataset):\n",
    "    \"\"\"Cassava dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, dataframe, root_dir, transforms=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe (string): dataframe train/valid\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.dataframe = dataframe\n",
    "        self.root_dir = root_dir\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def get_img_bgr_to_rgb(self, path):\n",
    "        im_bgr = cv2.imread(path)\n",
    "        im_rgb = im_bgr[:, :, ::-1]\n",
    "        return im_rgb\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.dataframe.iloc[idx, 0])\n",
    "        image = self.get_img_bgr_to_rgb(img_name)\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image=image)['image']\n",
    "        csv_row = self.dataframe.iloc[idx, 1:]\n",
    "        sample = {\n",
    "            'image': image, \n",
    "            'label': csv_row.label,\n",
    "        }\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-23T22:13:56.228359Z",
     "iopub.status.busy": "2023-04-23T22:13:56.227792Z",
     "iopub.status.idle": "2023-04-23T22:13:56.252614Z",
     "shell.execute_reply": "2023-04-23T22:13:56.252158Z",
     "shell.execute_reply.started": "2023-04-23T17:13:02.712488Z"
    },
    "papermill": {
     "duration": 0.051914,
     "end_time": "2023-04-23T22:13:56.252718",
     "exception": false,
     "start_time": "2023-04-23T22:13:56.200804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(DATA_PATH + \"train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019954,
     "end_time": "2023-04-23T22:13:56.292801",
     "exception": false,
     "start_time": "2023-04-23T22:13:56.272847",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Transforms using albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-23T22:13:56.339311Z",
     "iopub.status.busy": "2023-04-23T22:13:56.338616Z",
     "iopub.status.idle": "2023-04-23T22:13:56.341765Z",
     "shell.execute_reply": "2023-04-23T22:13:56.341247Z",
     "shell.execute_reply.started": "2023-04-23T17:13:03.115546Z"
    },
    "papermill": {
     "duration": 0.029099,
     "end_time": "2023-04-23T22:13:56.341851",
     "exception": false,
     "start_time": "2023-04-23T22:13:56.312752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_transforms():\n",
    "    return Compose([\n",
    "            A.RandomResizedCrop(sz, sz),\n",
    "            #A.Transpose(p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            #A.VerticalFlip(p=0.5),\n",
    "            #A.ShiftScaleRotate(p=0.5),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)\n",
    "\n",
    "\n",
    "def valid_transforms():\n",
    "    return Compose([\n",
    "            A.Resize(sz, sz),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020894,
     "end_time": "2023-04-23T22:13:56.383781",
     "exception": false,
     "start_time": "2023-04-23T22:13:56.362887",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model (modified to support SnapMix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-23T22:13:56.433167Z",
     "iopub.status.busy": "2023-04-23T22:13:56.432408Z",
     "iopub.status.idle": "2023-04-23T22:13:56.434830Z",
     "shell.execute_reply": "2023-04-23T22:13:56.435245Z",
     "shell.execute_reply.started": "2023-04-23T17:13:03.664947Z"
    },
    "papermill": {
     "duration": 0.03176,
     "end_time": "2023-04-23T22:13:56.435373",
     "exception": false,
     "start_time": "2023-04-23T22:13:56.403613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CassavaNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        backbone = timm.create_model(TIMM_MODEL, pretrained=True)\n",
    "        n_features = backbone.fc.in_features\n",
    "        self.backbone = nn.Sequential(*backbone.children())[:-2]\n",
    "        self.classifier = nn.Linear(n_features, 5)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        feats = self.forward_features(x)\n",
    "        x = self.pool(feats).view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x, feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019793,
     "end_time": "2023-04-23T22:13:56.475179",
     "exception": false,
     "start_time": "2023-04-23T22:13:56.455386",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-23T22:13:56.520284Z",
     "iopub.status.busy": "2023-04-23T22:13:56.519415Z",
     "iopub.status.idle": "2023-04-23T22:13:56.522582Z",
     "shell.execute_reply": "2023-04-23T22:13:56.522173Z",
     "shell.execute_reply.started": "2023-04-23T17:13:03.942165Z"
    },
    "papermill": {
     "duration": 0.027591,
     "end_time": "2023-04-23T22:13:56.522675",
     "exception": false,
     "start_time": "2023-04-23T22:13:56.495084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def accuracy_metric(input, targs):\n",
    "    return accuracy_score(targs.cpu(), input.cpu())\n",
    "\n",
    "def print_scores(scores):\n",
    "    kaggle_metric = np.average(scores)\n",
    "    print(\"Kaggle Metric: %f\" % (kaggle_metric))\n",
    "    \n",
    "    return kaggle_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-23T22:13:56.617145Z",
     "iopub.status.busy": "2023-04-23T22:13:56.616439Z",
     "iopub.status.idle": "2023-04-23T22:13:56.618582Z",
     "shell.execute_reply": "2023-04-23T22:13:56.619104Z",
     "shell.execute_reply.started": "2023-04-23T17:13:04.166406Z"
    },
    "papermill": {
     "duration": 0.07652,
     "end_time": "2023-04-23T22:13:56.619221",
     "exception": false,
     "start_time": "2023-04-23T22:13:56.542701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-23T22:13:56.665468Z",
     "iopub.status.busy": "2023-04-23T22:13:56.664768Z",
     "iopub.status.idle": "2023-04-23T22:13:56.667574Z",
     "shell.execute_reply": "2023-04-23T22:13:56.667171Z",
     "shell.execute_reply.started": "2023-04-23T17:13:04.821494Z"
    },
    "papermill": {
     "duration": 0.028358,
     "end_time": "2023-04-23T22:13:56.667665",
     "exception": false,
     "start_time": "2023-04-23T22:13:56.639307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def prec_recall_fscore(input, targs):\n",
    "    scores = precision_recall_fscore_support(targs.cpu(), input.cpu(), average='macro')\n",
    "    return {'precision': scores[0], 'recall': scores[1], 'fscore': scores[2], 'support': scores[3]} # return dictionary of 4 values\n",
    "\n",
    "def print_prec_recall_fscore(scores):\n",
    "    print(\"Precision Recall FScores Metric:\")\n",
    "    print(scores)\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.055672,
     "end_time": "2023-04-23T22:13:56.743638",
     "exception": false,
     "start_time": "2023-04-23T22:13:56.687966",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Checkpoint method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-23T22:13:56.791189Z",
     "iopub.status.busy": "2023-04-23T22:13:56.790388Z",
     "iopub.status.idle": "2023-04-23T22:13:56.793227Z",
     "shell.execute_reply": "2023-04-23T22:13:56.793612Z",
     "shell.execute_reply.started": "2023-04-23T17:13:05.328229Z"
    },
    "papermill": {
     "duration": 0.028877,
     "end_time": "2023-04-23T22:13:56.793727",
     "exception": false,
     "start_time": "2023-04-23T22:13:56.764850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def checkpoint(model, optimizer, epoch, current_metric, best_metric, fold):\n",
    "    print(\"Metric improved from %f to %f , Saving Model at Epoch #%d\" % (best_metric, current_metric, epoch))\n",
    "    ckpt = {\n",
    "        'model': CassavaNet(),\n",
    "        'state_dict': model.state_dict(),\n",
    "        #'optimizer' : optimizer.state_dict(),  # Commenting this out to cheap out on space\n",
    "        'metric': current_metric\n",
    "    }\n",
    "    torch.save(ckpt, 'ckpt_%s-%d-%d.pth' % (TIMM_MODEL, sz, fold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01975,
     "end_time": "2023-04-23T22:13:56.833265",
     "exception": false,
     "start_time": "2023-04-23T22:13:56.813515",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-23T22:13:56.881482Z",
     "iopub.status.busy": "2023-04-23T22:13:56.880695Z",
     "iopub.status.idle": "2023-04-23T22:13:56.883496Z",
     "shell.execute_reply": "2023-04-23T22:13:56.883070Z",
     "shell.execute_reply.started": "2023-04-23T17:13:05.759892Z"
    },
    "papermill": {
     "duration": 0.030341,
     "end_time": "2023-04-23T22:13:56.883592",
     "exception": false,
     "start_time": "2023-04-23T22:13:56.853251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "folds = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, \n",
    "                        random_state=SEED).split(np.arange(train_df.shape[0]), \n",
    "                                                 train_df.label.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021733,
     "end_time": "2023-04-23T22:13:56.925119",
     "exception": false,
     "start_time": "2023-04-23T22:13:56.903386",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SnapMix Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-23T22:13:56.991738Z",
     "iopub.status.busy": "2023-04-23T22:13:56.990958Z",
     "iopub.status.idle": "2023-04-23T22:13:56.993840Z",
     "shell.execute_reply": "2023-04-23T22:13:56.993420Z",
     "shell.execute_reply.started": "2023-04-23T17:13:06.330915Z"
    },
    "papermill": {
     "duration": 0.048687,
     "end_time": "2023-04-23T22:13:56.993961",
     "exception": false,
     "start_time": "2023-04-23T22:13:56.945274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "def get_spm(input,target,model):\n",
    "    imgsize = (sz, sz)\n",
    "    bs = input.size(0)\n",
    "    with torch.no_grad():\n",
    "        output,fms = model(input)\n",
    "        clsw = model.classifier\n",
    "        weight = clsw.weight.data\n",
    "        bias = clsw.bias.data\n",
    "        weight = weight.view(weight.size(0),weight.size(1),1,1)\n",
    "        fms = F.relu(fms)\n",
    "        poolfea = F.adaptive_avg_pool2d(fms,(1,1)).squeeze()\n",
    "        clslogit = F.softmax(clsw.forward(poolfea))\n",
    "        logitlist = []\n",
    "        for i in range(bs):\n",
    "            logitlist.append(clslogit[i,target[i]])\n",
    "        clslogit = torch.stack(logitlist)\n",
    "\n",
    "        out = F.conv2d(fms, weight, bias=bias)\n",
    "\n",
    "        outmaps = []\n",
    "        for i in range(bs):\n",
    "            evimap = out[i,target[i]]\n",
    "            outmaps.append(evimap)\n",
    "\n",
    "        outmaps = torch.stack(outmaps)\n",
    "        if imgsize is not None:\n",
    "            outmaps = outmaps.view(outmaps.size(0),1,outmaps.size(1),outmaps.size(2))\n",
    "            outmaps = F.interpolate(outmaps,imgsize,mode='bilinear',align_corners=False)\n",
    "\n",
    "        outmaps = outmaps.squeeze()\n",
    "\n",
    "        for i in range(bs):\n",
    "            outmaps[i] -= outmaps[i].min()\n",
    "            outmaps[i] /= outmaps[i].sum()\n",
    "\n",
    "\n",
    "    return outmaps,clslogit\n",
    "\n",
    "\n",
    "def snapmix(input, target, alpha, model=None):\n",
    "\n",
    "    r = np.random.rand(1)\n",
    "    lam_a = torch.ones(input.size(0))\n",
    "    lam_b = 1 - lam_a\n",
    "    target_b = target.clone()\n",
    "\n",
    "    if True:\n",
    "        wfmaps,_ = get_spm(input, target, model)\n",
    "        bs = input.size(0)\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "        lam1 = np.random.beta(alpha, alpha)\n",
    "        rand_index = torch.randperm(bs).cuda()\n",
    "        wfmaps_b = wfmaps[rand_index,:,:]\n",
    "        target_b = target[rand_index]\n",
    "\n",
    "        same_label = target == target_b\n",
    "        bbx1, bby1, bbx2, bby2 = rand_bbox(input.size(), lam)\n",
    "        bbx1_1, bby1_1, bbx2_1, bby2_1 = rand_bbox(input.size(), lam1)\n",
    "\n",
    "        area = (bby2-bby1)*(bbx2-bbx1)\n",
    "        area1 = (bby2_1-bby1_1)*(bbx2_1-bbx1_1)\n",
    "\n",
    "        if  area1 > 0 and  area>0:\n",
    "            ncont = input[rand_index, :, bbx1_1:bbx2_1, bby1_1:bby2_1].clone()\n",
    "            ncont = F.interpolate(ncont, size=(bbx2-bbx1,bby2-bby1), mode='bilinear', align_corners=True)\n",
    "            input[:, :, bbx1:bbx2, bby1:bby2] = ncont\n",
    "            lam_a = 1 - wfmaps[:,bbx1:bbx2,bby1:bby2].sum(2).sum(1)/(wfmaps.sum(2).sum(1)+1e-8)\n",
    "            lam_b = wfmaps_b[:,bbx1_1:bbx2_1,bby1_1:bby2_1].sum(2).sum(1)/(wfmaps_b.sum(2).sum(1)+1e-8)\n",
    "            tmp = lam_a.clone()\n",
    "            lam_a[same_label] += lam_b[same_label]\n",
    "            lam_b[same_label] += tmp[same_label]\n",
    "            lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (input.size()[-1] * input.size()[-2]))\n",
    "            lam_a[torch.isnan(lam_a)] = lam\n",
    "            lam_b[torch.isnan(lam_b)] = 1-lam\n",
    "\n",
    "    return input,target,target_b,lam_a.cuda(),lam_b.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020035,
     "end_time": "2023-04-23T22:13:57.034207",
     "exception": false,
     "start_time": "2023-04-23T22:13:57.014172",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SnapMix Criterion (Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-23T22:13:57.080626Z",
     "iopub.status.busy": "2023-04-23T22:13:57.079685Z",
     "iopub.status.idle": "2023-04-23T22:13:57.082568Z",
     "shell.execute_reply": "2023-04-23T22:13:57.082154Z",
     "shell.execute_reply.started": "2023-04-23T17:13:06.810147Z"
    },
    "papermill": {
     "duration": 0.028478,
     "end_time": "2023-04-23T22:13:57.082665",
     "exception": false,
     "start_time": "2023-04-23T22:13:57.054187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SnapMixLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, criterion, outputs, ya, yb, lam_a, lam_b):\n",
    "        loss_a = criterion(outputs, ya)\n",
    "        loss_b = criterion(outputs, yb)\n",
    "        loss = torch.mean(loss_a * lam_a + loss_b * lam_b)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020077,
     "end_time": "2023-04-23T22:13:57.122679",
     "exception": false,
     "start_time": "2023-04-23T22:13:57.102602",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train & Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-23T22:13:57.167650Z",
     "iopub.status.busy": "2023-04-23T22:13:57.166801Z",
     "iopub.status.idle": "2023-04-23T23:31:41.537225Z",
     "shell.execute_reply": "2023-04-23T23:31:41.537719Z",
     "shell.execute_reply.started": "2023-04-23T21:47:27.371364Z"
    },
    "papermill": {
     "duration": 4664.395244,
     "end_time": "2023-04-23T23:31:41.537913",
     "exception": false,
     "start_time": "2023-04-23T22:13:57.142669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rsb-weights/resnet50_a1_0-14fe96d1.pth\" to /root/.cache/torch/hub/checkpoints/resnet50_a1_0-14fe96d1.pth\n",
      "{'Epoch': 1, 'train_loss': 5.4652}: 100%|██████████| 534/534 [06:39<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': 1, 'train_loss': 5.4652, 'val_loss': 1.4551}\n",
      "Kaggle Metric: 0.614661\n",
      "Metric improved from 0.000000 to 0.614661 , Saving Model at Epoch #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 2, 'train_loss': 1.5104}: 100%|██████████| 534/534 [06:29<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': 2, 'train_loss': 1.5104, 'val_loss': 1.5308}\n",
      "Kaggle Metric: 0.614661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 3, 'train_loss': 1.5119}: 100%|██████████| 534/534 [06:29<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': 3, 'train_loss': 1.5119, 'val_loss': 1.5417}\n",
      "Kaggle Metric: 0.614661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 4, 'train_loss': 1.5155}: 100%|██████████| 534/534 [06:29<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': 4, 'train_loss': 1.5155, 'val_loss': 1.4252}\n",
      "Kaggle Metric: 0.614661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 5, 'train_loss': 1.5173}: 100%|██████████| 534/534 [06:29<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': 5, 'train_loss': 1.5173, 'val_loss': 1.4917}\n",
      "Kaggle Metric: 0.614661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 6, 'train_loss': 1.5124}: 100%|██████████| 534/534 [06:29<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': 6, 'train_loss': 1.5124, 'val_loss': 1.5376}\n",
      "Kaggle Metric: 0.614661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 7, 'train_loss': 1.5095}: 100%|██████████| 534/534 [06:30<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': 7, 'train_loss': 1.5095, 'val_loss': 1.501}\n",
      "Kaggle Metric: 0.614661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 8, 'train_loss': 1.5197}: 100%|██████████| 534/534 [06:30<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': 8, 'train_loss': 1.5197, 'val_loss': 1.4894}\n",
      "Kaggle Metric: 0.614661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 9, 'train_loss': 1.5164}: 100%|██████████| 534/534 [06:30<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': 9, 'train_loss': 1.5164, 'val_loss': 1.4537}\n",
      "Kaggle Metric: 0.614661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 10, 'train_loss': 1.5176}: 100%|██████████| 534/534 [06:30<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': 10, 'train_loss': 1.5176, 'val_loss': 1.4885}\n",
      "Kaggle Metric: 0.614661\n"
     ]
    }
   ],
   "source": [
    "for fold_num, (train_split, valid_split) in enumerate(folds):\n",
    "    train_set = train_df.iloc[train_split].reset_index(drop=True)\n",
    "    valid_set = train_df.iloc[valid_split].reset_index(drop=True)\n",
    "    \n",
    "    train_ds = CassavaDataset(dataframe=train_set,\n",
    "                          root_dir=DATA_PATH + 'train_images',\n",
    "                          transforms=train_transforms())\n",
    "    \n",
    "    valid_ds = CassavaDataset(dataframe=valid_set,\n",
    "                          root_dir=DATA_PATH + 'train_images',\n",
    "                          transforms=valid_transforms())\n",
    "    \n",
    "    train_dl = torch.utils.data.DataLoader(train_ds, batch_size=bs, \n",
    "                                           shuffle=True, num_workers=8, drop_last=True,\n",
    "                                           pin_memory=True)\n",
    "    valid_dl = torch.utils.data.DataLoader(valid_ds, batch_size=bs, \n",
    "                                           shuffle=False, num_workers=8, \n",
    "                                           pin_memory=True)\n",
    "    \n",
    "    losses = []\n",
    "    batches = len(train_dl)\n",
    "    val_batches = len(valid_dl)\n",
    "    best_metric = 0\n",
    "    \n",
    "    model = CassavaNet().to(device)\n",
    "    criterion = nn.CrossEntropyLoss(reduction='none').to(device)\n",
    "    val_criterion = nn.CrossEntropyLoss().to(device)\n",
    "    snapmix_criterion = SnapMixLoss().to(device)\n",
    "    param_groups = [\n",
    "       {'params': model.backbone.parameters(), 'lr': 1e-2},\n",
    "       {'params': model.classifier.parameters()},\n",
    "    ]\n",
    "    optimizer = torch.optim.SGD(param_groups, lr=1e-1, momentum=0.9, weight_decay=1, nesterov=True)\n",
    "    # optimizer = torch.optim.Adam(param_groups, lr=1e-1, weight_decay=1e-4)\n",
    "    \n",
    "    # scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[1,20,40], gamma=0.1, last_epoch=-1, verbose=True)\n",
    "    \n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        # ----------------- TRAINING  ----------------- \n",
    "        train_loss = 0\n",
    "        progress = tqdm(enumerate(train_dl), desc=\"Loss: \", total=batches)\n",
    "\n",
    "        model.train()\n",
    "        for i, data in progress:\n",
    "            image, label = data.values()\n",
    "            X, y = image.to(device).float(), label.to(device).long()\n",
    "            \n",
    "            with autocast():\n",
    "                \n",
    "                rand = np.random.rand()\n",
    "                if rand > (1.0-SNAPMIX_PCT):\n",
    "                    X, ya, yb, lam_a, lam_b = snapmix(X, y, SNAPMIX_ALPHA, model)\n",
    "                    outputs, _ = model(X)\n",
    "                    loss = snapmix_criterion(criterion, outputs, ya, yb, lam_a, lam_b)\n",
    "                else:\n",
    "                    outputs, _ = model(X)\n",
    "                    loss = torch.mean(criterion(outputs, y))\n",
    "                \n",
    "            scaler.scale(loss).backward()\n",
    "            # Accumulate gradients\n",
    "            if ((i + 1) % GRAD_ACCUM_STEPS == 0) or ((i + 1) == len(train_dl)):\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            cur_step = i+1\n",
    "            trn_epoch_result = dict()\n",
    "            trn_epoch_result['Epoch'] = epoch + 1\n",
    "            trn_epoch_result['train_loss'] = round(train_loss/cur_step, 4)\n",
    "\n",
    "            progress.set_description(str(trn_epoch_result))\n",
    "\n",
    "        # scheduler.step()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        # ----------------- VALIDATION  ----------------- \n",
    "        val_loss = 0\n",
    "        scores = []\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(valid_dl):\n",
    "                image, label = data.values()\n",
    "                X, y = image.to(device), label.to(device)\n",
    "                outputs, _ = model(X)\n",
    "                l = val_criterion(outputs, y)\n",
    "                val_loss += l.item()\n",
    "\n",
    "                preds = F.softmax(outputs).argmax(axis=1)\n",
    "                scores.append(accuracy_metric(preds, y))\n",
    "\n",
    "        epoch_result = dict()\n",
    "        epoch_result['Epoch'] = epoch + 1\n",
    "        epoch_result['train_loss'] = round(train_loss/batches, 4)\n",
    "        epoch_result['val_loss'] = round(val_loss/val_batches, 4)\n",
    "\n",
    "        print(epoch_result)\n",
    "\n",
    "        # Check if we need to save\n",
    "        current_metric = print_scores(scores)\n",
    "        if current_metric > best_metric:\n",
    "            checkpoint(model, optimizer, epoch+1, current_metric, best_metric, fold_num)\n",
    "            best_metric = current_metric\n",
    "            \n",
    "    del model, optimizer, train_dl, valid_dl, scaler\n",
    "    # del model, optimizer, train_dl, valid_dl, scaler, scheduler\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Train only a single fold\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 2.699815,
     "end_time": "2023-04-23T23:31:46.889557",
     "exception": false,
     "start_time": "2023-04-23T23:31:44.189742",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "*Please Upvote if you liked the kernel ! Cheers.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-23T23:31:52.256317Z",
     "iopub.status.busy": "2023-04-23T23:31:52.255670Z",
     "iopub.status.idle": "2023-04-23T23:31:52.266368Z",
     "shell.execute_reply": "2023-04-23T23:31:52.266798Z"
    },
    "papermill": {
     "duration": 2.702841,
     "end_time": "2023-04-23T23:31:52.266996",
     "exception": false,
     "start_time": "2023-04-23T23:31:49.564155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Recall FScores Metric:\n",
      "{'precision': 0.14583333333333334, 'recall': 0.25, 'fscore': 0.18421052631578946, 'support': None}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': 0.14583333333333334,\n",
       " 'recall': 0.25,\n",
       " 'fscore': 0.18421052631578946,\n",
       " 'support': None}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_prec_recall_fscore(prec_recall_fscore(preds, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 3.23388,
     "end_time": "2023-04-23T23:31:58.090523",
     "exception": false,
     "start_time": "2023-04-23T23:31:54.856643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 4710.181104,
   "end_time": "2023-04-23T23:32:01.298545",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-23T22:13:31.117441",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
